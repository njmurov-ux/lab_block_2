---
title: "Block 1 Lab 2 report"
author: "Group B13: Aron(aroen488), Sergey(servo519), Shahin(mdpa888)"
date: "2025-11-26"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning = FALSE,
  message = FALSE 
)

```
## Statement of Contribution



## Assignment 1. 

## Assignment 2. 

### Task 1

```{r task_2_functions}
#######################
#
# TASK 2 CODE
#
#######################
library(data.table)
library(rpart)
library(knitr)

data <- fread('data/bank-full.csv', stringsAsFactors = FALSE)
data$duration <- NULL
# Define categorical columns for which to determine levels dynamically
categorical_cols <- c('job', 'marital', 'education', 'default', 'housing', 'loan',
                      'contact', 'month', 'day', 'poutcome', 'y')

# Convert each categorical variable to a factor based on its own unique levels
for (col in categorical_cols) {
  
  data[[col]] <- factor(data[[col]], levels = unique(data[[col]]))
}

str(data)  # to check data structure
n=dim(data)[1]
set.seed(12345) 
id=sample(1:n, floor(n*0.4)) 
train=data[id,] 
id1=setdiff(1:n, id)
set.seed(12345) 
id2=sample(id1, floor(n*0.3)) 
valid=data[id2,]
id3=setdiff(id1,id2)
test=data[id3,]
```

After splitting the data into training/test/validation at the 40/30/30 ratio, we have `r nrow(train)`/`r nrow(valid)`/`r nrow(test)` rows in each respective dataset.

### Task 2

```{r}

# a. Decision tree with default settings
tree_default <- rpart(y ~ ., data = train, method = "class")

# b. Decision tree with smallest allowed node size (minbucket) = 7000
tree_minbucket <- rpart(y ~ ., data = train, method = "class", control = rpart.control(minbucket = 7000))

# c. Decision tree with minimum deviance (mindev) = 0.0005
# Note: rpart does not have a mindev control parameter; deviance threshold is controlled differently by 'cp'
# We first need to obtain the deviance at the root node and then calculate the ratio between our
# absolute minimum deviance threshold of 0.0005 and that to use the output as the input to the cp
# parameter in rpart

tmp <- rpart(y ~ ., data = train, method = "class",
             control = rpart.control(cp = 0.0, xval = 0))
D_root <- tmp$frame$dev[1]  # deviance at the root node
mindev_target <- 0.0005  # absolute deviance reduction we want
cp_val <- mindev_target / D_root

# tree_cp <- rpart(y ~ ., data = train, method = "class", control = rpart.control(cp = 0.0005))
tree_cp <- rpart(y ~ ., data = train, method = "class", control = rpart.control(cp = cp_val))

misclass_rate <- function(model, data) {
  pred <- predict(model, newdata = data, type = "class")
  mean(pred != data$y)
}

# Calculate misclassification rates
results <- data.frame(
  Model = c("Default", "Minbucket 7000", "CP 0.0005"),
  Train_Misclass = c(misclass_rate(tree_default, train),
                     misclass_rate(tree_minbucket, train),
                     misclass_rate(tree_cp, train)),
  Valid_Misclass = c(misclass_rate(tree_default, valid),
                     misclass_rate(tree_minbucket, valid),
                     misclass_rate(tree_cp, valid))
)

print(results)

# library(tree)
# 
# # a. Decision tree with default settings
# tree_default <- tree(y ~ ., data = train)
# 
# # b. Decision tree with minimum node size = 7000
# tree_minsize <- tree(y ~ ., data = train, control = tree.control(nobs = nrow(train), mincut = 7000))
# 
# # c. Minimum deviance of 0.0005 
# 
# tree_mindev <- tree(y ~ ., data = train, control = tree.control(nobs = nrow(train), mindev = 0.0005))
# 
# # Function to calculate misclassification rate
# misclass_rate <- function(model, data) {
#   pred <- predict(model, newdata = data, type = "class")
#   mean(pred != data$y)
# }
# 
# # Calculate misclassification rates
# results <- data.frame(
#   Model = c("Default", "Minsize 7000", "MinDev k=0.0005"),
#   Train_Misclass = c(misclass_rate(tree_default, train),
#                      misclass_rate(tree_minsize, train),
#                      misclass_rate(tree_mindev, train)),
#   Valid_Misclass = c(misclass_rate(tree_default, valid),
#                      misclass_rate(tree_minsize, valid),
#                      misclass_rate(tree_mindev, valid))
# )
# 
# print(results)
# 
# # Count number of splits for each tree
# num_splits_default  <- sum(!tree_default$frame$var == "<leaf>")
# num_splits_minsize  <- sum(!tree_minsize$frame$var == "<leaf>")
# num_splits_mindev   <- sum(!tree_mindev$frame$var == "<leaf>")
# 
# cat("Default tree splits:", num_splits_default, "\n")
# cat("Minsize 7000 tree splits:", num_splits_minsize, "\n")
# cat("MinDev k=0.0005 tree splits:", num_splits_mindev, "\n")
# 
# # In R, set multi-plot window for side-by-side plots
# par(mfrow = c(1, 3))
# 
# # Plot each tree, with split count in the title
# plot(tree_default, main = paste("Default\nSplits:", num_splits_default))
# text(tree_default, cex=0.7)
# 
# plot(tree_minsize, main = paste("Minsize=7000\nSplits:", num_splits_minsize))
# text(tree_minsize, cex=0.7)
# 
# plot(tree_mindev, main = paste("MinDev=0.0005\nSplits:", num_splits_mindev))
# text(tree_mindev, cex=0.7)
# 
# # Reset plotting window
# par(mfrow = c(1, 1))
num_splits <- c(
  Default = length(tree_default$frame$var[tree_default$frame$var != "<leaf>"]),
  Minbucket7000 = length(tree_minbucket$frame$var[tree_minbucket$frame$var != "<leaf>"]),
  CP_0.0005 = length(tree_cp$frame$var[tree_cp$frame$var != "<leaf>"])
)

print(num_splits)

library(rpart.plot)

# Plot 3 original trees side-by-side for comparison
par(mfrow = c(1, 3))

rpart.plot(tree_default, main = "Default Settings")
rpart.plot(tree_minbucket, main = "Minbucket = 7000")
rpart.plot(tree_cp, main = "cp = 0.0005")

par(mfrow = c(1, 1))
```

- Default: uses reasonable default parameters, only 1 split, relatively low bias and low variance
- Min bucket 7000: no split at all as child nodes are all smaller than 7000. This is just assigning all instances to the dominant class
- Min dev = 0.0005: Very many leaves, low bias but the highest variance, clear signs of overfitting. We need to prune this tree.


### Task 3

```{r}
n_leaves <- function(fit) sum(fit$frame$var == "<leaf>")

# helper: deviance on a dataset (negative log-lik up to a constant)
tree_deviance <- function(fit, data) {
  p_hat <- predict(fit, newdata = data, type = "prob")
  y <- data$y
  idx <- cbind(seq_len(nrow(p_hat)), match(y, colnames(p_hat)))
  -2 * mean(log(p_hat[idx]))
}

cp_seq <- tree_cp$cptable[, "CP"]

dev_list <- lapply(seq_along(cp_seq), function(i) {
  fit_i <- prune(tree_cp, cp = cp_seq[i])
  data.frame(
    cp        = cp_seq[i],
    leaves    = n_leaves(fit_i),
    train_dev = tree_deviance(fit_i, train),
    valid_dev = tree_deviance(fit_i, valid)
  )
})

dev_df <- do.call(rbind, dev_list)
dev_df_50 <- subset(dev_df, leaves <= 50)

library(ggplot2)

ggplot(dev_df_50, aes(x = leaves)) +
  geom_line(aes(y = train_dev, colour = "Train")) +
  geom_line(aes(y = valid_dev, colour = "Validation")) +
  labs(x = "Number of leaves", y = "Deviance", colour = "Data") +
  theme_minimal()

# Optimal subtree (within 50 leaves) by validation deviance
opt_row <- dev_df_50[which.min(dev_df_50$valid_dev), ]
opt_leaves <- opt_row$leaves
opt_cp     <- opt_row$cp

tree_opt <- prune(tree_cp, cp = opt_cp)
print(paste("Optimal number of leaves:", opt_leaves))
```

For a classification model that predicts class probabilities $\hat{p}_{i,k}$ for each
observation $i = 1, \dots, n$ and class $k = 1, \dots, K$, the (mean) deviance is

$$
D = -\frac{2}{n} \sum_{i=1}^n \sum_{k=1}^K y_{i,k} \log\bigl(\hat{p}_{i,k}\bigr),
$$

where

- $n$ is the number of observations in the dataset.
- $K$ is the number of classes.
- $y_{i,k}$ is an indicator variable:
  $y_{i,k} = 1$ if observation $i$ belongs to class $k$, and $0$ otherwise.
- $\hat{p}_{i,k}$ is the predicted probability (from the model) that
  observation $i$ belongs to class $k$.
- $D$ is the (average) deviance: lower values of $D$ indicate a better fit.

In the special case of binary classification with response $y_i \in \{0,1\}$ and
predicted probability $\hat{p}_i = P(y_i = 1)$, this simplifies to

$$
D = -\frac{2}{n} \sum_{i=1}^n \Bigl[
  y_i \log(\hat{p}_i) + (1 - y_i)\log(1 - \hat{p}_i)
\Bigr].
$$

Here

- $y_i$ is the observed class for observation $i$ (1 for “success”, 0 for “failure”),
- $\hat{p}_i$ is the predicted probability of class 1 for observation $i$.

As the number of leaves increases, the training deviance decreases monotonically, while the validation deviance initially decreases and then increases, forming a U‑shaped curve. For very small trees (few leaves), both training and validation deviances are high, indicating underfitting and high bias. As we allow more leaves, the model becomes more flexible, bias decreases, and validation deviance improves, reaching its minimum at 16 leaves. Beyond 16 leaves, further increases in tree size continue to reduce training deviance but lead to higher validation deviance, which indicates that additional complexity mainly increases variance and causes overfitting. Thus a tree with 16 leaves provides the best bias–variance tradeoff.


```{r}
# Variable importance
sort(tree_opt$variable.importance, decreasing = TRUE)
```

- Most important: poutcome (outcome of previous marketing campaign) and month (month of contact).

- Next tier: day of the month, pdays (days since last contact), and contact type.

- Less important but still used: job, balance, campaign.

- Barely used: age, previous, education, default (almost no contribution).

The tree mainly bases its decisions on past campaign outcome and timing of the contact, with customer/job characteristics playing a smaller role.

```{r}
models <- list(
  "Default"        = tree_default,
  "Minbucket 7000" = tree_minbucket,
  "CP 0.0005"      = tree_cp,
  "Optimal 16-leaf" = tree_opt    # if you have your pruned tree
)

misclass_df <- do.call(rbind, lapply(models, function(m) {
  c(
    Train = misclass_rate(m, train),
    Valid = misclass_rate(m, valid)
  )
}))

misclass_df <- data.frame(
  Model = rownames(misclass_df),
  Train_Misclass = misclass_df[, "Train"],
  Valid_Misclass = misclass_df[, "Valid"],
  row.names = NULL
)

kable(
  misclass_df,
  digits = 3,
  caption = "Train and validation misclassification rates for tree models"
)
```
The 16‑leaf tree chosen by minimum validation deviance has essentially the same validation misclassification rate as the default tree that only splits on *poutcome*. However, the 16‑leaf tree achieves a lower validation deviance, indicating that its predicted probabilities are better calibrated and capture more nuanced structure in the data. In terms of the bias–variance tradeoff, it reduces bias (better fit) without noticeably reducing 0–1 error on the validation set.

```{r}
# Plot the tree for interpretation
library(rpart.plot)
rpart.plot(tree_opt, type = 2, extra = 104)
```

Key findings:

- Previous campaign success is the single most informative variable, essentially splitting the population into a low‑propensity group and a high‑propensity group.

- Timing matters: both within the non‑success and success groups, the specific month and day of contact have substantial influence, suggesting seasonality or within‑month effects in customer responsiveness.

- Customer profile variables such as job and balance play a secondary, fine‑tuning role: they help pick out especially promising or unpromising subsegments but do not overturn the primary pattern driven by past outcome and timing.

## Assignment 3. 


## Assignment 4. 





## Appendix


```{r, ref.label=setdiff(knitr::all_labels(), c('setup')), echo=TRUE, eval=FALSE}



```
